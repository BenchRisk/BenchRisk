Risk ID Mitigated,Mitigation Number,Reduction in Likelihood (Percent),Reduction in Severity (Percent),Risk Short Description,Response Measure Description,Notes,Reformatted as a Question
#001,1,80.00,25.00,The information provided by the benchmark does not match with the information the benchmark user believes is provided,"Clearly, publicly, and prominently state the user information foraging (i.e., what the user wants to learn) task associated with the evaluation. This should be provided in plain and concise language accessible to the intended users of the benchmark",,"Do you clearly, publicly, and prominently state the user information foraging task associated with your benchmark evaluation—using plain and concise language that is accessible to the intended users? By 'information foraging task,' we mean the specific goal or question that a user is trying to answer or learn about when engaging with the benchmark, reflecting their real-world information needs."
#001,106,56.67,25.00,The information provided by the benchmark does not match with the information the benchmark user believes is provided,Use cases or user personas of the person relying on the benchmark are described,,Do you describe the use cases or the user personas of those who will rely on the benchmark?
#001,186,70.00,25.00,The information provided by the benchmark does not match with the information the benchmark user believes is provided,"Provide task taxonomy showing how the input/output space corresponds to different classes of hazards, failures, or compliant/non-compliant prompts and output",,"Do you provide a task taxonomy that shows how the input/output space maps to hazards, failures, or compliant/non-compliant prompts and outputs?"
#001,198,63.33,33.33,The information provided by the benchmark does not match with the information the benchmark user believes is provided,"Clearly, publicly, and prominently state the user information foraging task associated with the evaluation. This can be provided in a manner only accessible to sophisticated (e.g., LLM engineers) users.",,"Do you clearly, publicly, and prominently state the user information foraging task associated with the evaluation, even if only for sophisticated users such as LLM engineers?"
#002,64,50.00,33.33,The task is defined too broadly to achieve any reasonable degree of coverage over the use case,"Prominently state that the benchmark does not cover the input space (i.e., that this is a low coverage benchmark)",,"Do you prominently state that the benchmark does not fully cover the input space, and clarify its limitations in coverage?"
#002,68,63.33,33.33,The task is defined too broadly to achieve any reasonable degree of coverage over the use case,"Reduce the scope of the benchmark until it is possible to achieve comprehensive coverage of the input space (i.e., ensure that high coverage is possible)",,Do you reduce the scope of the benchmark to ensure comprehensive coverage of the input space is achievable?
#002,162,46.67,54.17,The task is defined too broadly to achieve any reasonable degree of coverage over the use case,List and make available a complete definition of what is and is not covered by the benchmark.,,Do you list and make available a complete definition of what is and isn’t covered by the benchmark?
#002,187,53.33,45.83,The task is defined too broadly to achieve any reasonable degree of coverage over the use case,"Split the benchmark into smaller, focused subtasks and present scores for those tasks separately.",,"Have you split the benchmark into smaller, focused subtasks and presented scores for those subtasks separately?"
#002,188,63.33,41.67,The task is defined too broadly to achieve any reasonable degree of coverage over the use case,"Sample prompts from the input space according to their likelihood of occurring in the real world (e.g., analyze prompt distributions from an already deployed system)",,"Do you sample prompts from the input space according to their real-world likelihood of occurrence (e.g., based on analysis of deployed systems)?"
#002,189,36.67,45.83,The task is defined too broadly to achieve any reasonable degree of coverage over the use case,Visualize what parts of the input space are covered vs. missing and present the visualization to relying users.,,Do you visualize and share what parts of the input space are covered versus missing?
#002,190,43.33,66.67,The task is defined too broadly to achieve any reasonable degree of coverage over the use case,Report coverage metrics for the task space,,Do you report metrics indicating coverage of the task space?
#002,191,40.00,50.00,The task is defined too broadly to achieve any reasonable degree of coverage over the use case,Red team the evaluation to find those regions of the input space that are most needing coverage and use them to generate additional data,,Have you red-teamed the evaluation to identify undercovered input space regions and generated additional data for those areas?
#003,2,83.33,45.83,Input prompt writers produce prompts with LLMs,Contractually prohibit use of LLMs in the production of test data,,Do you contractually prohibit the use of large language models (LLMs) in the production of test data for your benchmark?
#003,3,46.67,54.17,Input prompt writers produce prompts with LLMs,Record specification of the LLM used for every prompt produced with the aid of an LLM,,Do you record the specification of the LLM used for every prompt that was produced with the aid of an LLM?
#003,4,43.33,54.17,Input prompt writers produce prompts with LLMs,Run a study on any SUT potentially privileged via prompt generation and compare to those SUTs not involved in prompt generation. Drop LLM-generated instances if unfair advantage conferred.,,"Do you run a study on any system under test (SUT) that may have been privileged during prompt generation, and compare its performance to SUTs not involved in prompt generation? If an unfair advantage is found, do you drop the LLM-generated instances?"
#003,70,33.33,66.67,Input prompt writers produce prompts with LLMs,Produce a sufficient number of human-generated prompts to enable a statistical analysis of the LLM generated prompts and run a comparative study,,"Do you generate a sufficient number of human-written prompts to enable statistical comparison with LLM-generated prompts, and do you conduct a comparative study?"
#003,89,86.67,62.50,Input prompt writers produce prompts with LLMs,"Benchmark authors produce all prompts without the aid of data vendor, LLMs, or crowd workers whose identity is not known to the benchmark authors. ",,"Are all prompts authored by the benchmark creators themselves, without using data vendors, LLMs, or crowd workers whose identities are unknown to the authors?"
#003,163,46.67,58.33,Input prompt writers produce prompts with LLMs,"Construct the task definition such that LLMs are of limited utility in the production of the prompts (i.e., most prompts could not be produced with the aid of LLMs at the time of prompt writing)",,Do you construct the task definition such that LLMs are of limited utility in producing the prompts?
#003,192,50.00,33.33,Input prompt writers produce prompts with LLMs,Audit prompts by looking at samplings of the test set to check for problems or indications of undisclosed utilization of LLMs in the production of prompts,,Do you audit test set prompts for issues such as signs of undisclosed use of LLMs in their generation?
#003,199,66.67,41.67,Input prompt writers produce prompts with LLMs,Benchmark was produced prior to broad availability of LLMs capable of producing the benchmark's prompts,,Was the benchmark produced before the widespread availability of LLMs capable of generating its prompts?
#004,5,80.00,54.17,Prompts are collected from publicly available sources that are also likely to be in the datasets of SUT developers,Avoid sourcing from publicly available information,,Do you avoid sourcing data from publicly available information when constructing your benchmark?
#004,6,33.33,41.67,Prompts are collected from publicly available sources that are also likely to be in the datasets of SUT developers,Search the web for data in the prompt set,,Do you search the web for data included in your prompt set to find undisclosed collection from publicly available sources?
#004,140,83.33,41.67,Prompts are collected from publicly available sources that are also likely to be in the datasets of SUT developers,Produce entirely new prompts with the aid of humans,,Do you produce entirely new prompts with the aid of humans?
#005,7,56.67,29.17,Data vendor licenses private data that is available to other parties,Prohibit data vendor from re-licensing data to the benchmark authors that is itself licensed by the data vendor from a third party,,Do you prohibit data vendors from re-licensing to you any data that they originally licensed from a third party?
#005,8,73.33,25.00,Data vendor licenses private data that is available to other parties,Contractually prohibit the data vendor from acquiring data rights and providing those data to the benchmark authors,,Do you include contractual prohibitions against providing data that might be available to other parties?
#005,101,96.67,37.50,Data vendor licenses private data that is available to other parties,Benchmark authors produce all root prompts (prompts may be augmented further with language models) from original human effort without sourcing data from external sources,,Do you ensure that all prompts are produced solely through original human effort without sourcing data from external sources?
#006,9,73.33,16.67,Data vendor provides same prompts to multiple organizations including benchmark authors and SUT developers,Prohibit vendor licensing data to multiple parties contractually,,Do you include contractual prohibitions against reselling licensed data to unrelated parties in your agreements with data vendors?
#006,102,73.33,16.67,Data vendor provides same prompts to multiple organizations including benchmark authors and SUT developers,Benchmark authors supervise the production of all prompts from original human effort by requiring any external party to produce novel previously unwritten and undigitized prompts,,"Do you supervise prompt production by requiring that any external party generates only novel, previously unwritten, and undigitized prompts?"
#006,141,93.33,45.83,Data vendor provides same prompts to multiple organizations including benchmark authors and SUT developers,All prompts are entirely new and produced in-house by the benchmark developers,,Are all prompts entirely new and produced in-house by the benchmark developers?
#007,10,46.67,62.50,"Singular prompts without a distributional tie lack a capacity for detecting distributional failings, harms, or impacts","State the limitations of the current benchmark with respect to disparate failings, harms, or impacts(i.e., differential performance or rates of negative/positive outcomes according to a property upon which system behavior should not vary, including but not limited to protected classes)",,"Do you disclose distributional limitations (e.g., that the benchmark does not provide information on distributional harms such as disparate impact) of the benchmark?"
#007,62,83.33,58.33,"Singular prompts without a distributional tie lack a capacity for detecting distributional failings, harms, or impacts","Produce data with distributional association capable of detecting disparate failings, harms, or impacts",,Do you produce data with distributional associations when designing your benchmark?
#008,11,53.33,41.67,"Prompt writers produce prompts with inadequate variability within the valid input space (e.g., a single prompt writer writes all the prompts)",Analyze prompt length and embedding space distribution visually,,Do you analyze the prompt length and/or the embedding space of prompts visually?
#008,69,56.67,33.33,"Prompt writers produce prompts with inadequate variability within the valid input space (e.g., a single prompt writer writes all the prompts)",Source prompts from multiple populations with distinct prompt writer demographic attributes,,Do you source prompts from multiple populations with clearly distinct demographic characteristics among prompt writers?
#008,142,56.67,54.17,"Prompt writers produce prompts with inadequate variability within the valid input space (e.g., a single prompt writer writes all the prompts)",Define the information foraging task of the benchmark relying user in such a way that coverage over the input space can be sampled rather than comprehensive,,Do you define the information foraging task of the benchmark-relying user in a way that allows for sampling over the input space rather than requiring comprehensive coverage?
#008,164,73.33,50.00,"Prompt writers produce prompts with inadequate variability within the valid input space (e.g., a single prompt writer writes all the prompts)",Involve domain experts in the production of the prompts to ensure all known forms of variation are covered,,Do you involve domain experts in producing the prompts to ensure all known forms of variation are covered by the inputs?
#009,12,43.33,41.67,Adversarial prompt bulking (increasing the number of prompts by multiplying them by the number of tactics),"State sample count in terms of root samples and templates (i.e., structured expressions of inputs subject to perturbation or instantiation) or are there no templates?",,"Do you state sample counts in terms of root samples and templates (i.e., structured expressions of inputs subject to perturbation or instantiation)? Templates may be excluded entirely from the design."
#009,84,53.33,41.67,Adversarial prompt bulking (increasing the number of prompts by multiplying them by the number of tactics),Analyze prompt length and embedding space distribution visually,,Do you analyze prompt length and embedding space distribution visually to understand prompt variability?
#009,86,46.67,33.33,Adversarial prompt bulking (increasing the number of prompts by multiplying them by the number of tactics),Source prompts from multiple populations with distinct prompt writer demographic attributes,,Do you source prompts from multiple populations with distinct demographic attributes of the prompt writers?
#009,165,86.67,58.33,Adversarial prompt bulking (increasing the number of prompts by multiplying them by the number of tactics),The task as defined does not examine adversarial performance and adversarial prompts are not included,,"Is the task defined in a way that does not examine adversarial performance, and are adversarial prompts excluded?"
#009,178,70.00,37.50,Adversarial prompt bulking (increasing the number of prompts by multiplying them by the number of tactics),All prompts are sourced from real users under normal circumstances,,Are all prompts sourced from real users under normal circumstances?
#009,183,56.67,29.17,Adversarial prompt bulking (increasing the number of prompts by multiplying them by the number of tactics),Data is collected from publicly available sources that have no directive or incentive to adversarially bulk the number of prompts,,Is your data collected from publicly available sources with no incentive or directive to adversarially inflate the number of prompts?
#010,13,50.00,33.33,Prompt perturbation bulking (increasing the number of prompts by making small changes to root prompts),"State sample count in terms of root samples and templates (i.e., structured expressions of inputs subject to perturbation or instantiation) or are there no templates?",,"Do you state sample counts in terms of root samples and templates (i.e., structured expressions of inputs subject to perturbation or instantiation)? Templates may be excluded entirely from the design."
#010,85,40.00,45.83,Prompt perturbation bulking (increasing the number of prompts by making small changes to root prompts),Analyze prompt length and embedding space distribution visually,,Do you analyze prompt length and embedding space distribution visually to understand prompt variability?
#010,87,36.67,45.83,Prompt perturbation bulking (increasing the number of prompts by making small changes to root prompts),Source prompts from multiple populations with distinct prompt writer demographic attributes,,Do you source prompts from multiple populations with distinct demographic attributes of the prompt writers?
#010,184,73.33,45.83,Prompt perturbation bulking (increasing the number of prompts by making small changes to root prompts),Data is collected from publicly available sources that have no directive or incentive to adversarially bulk the number of prompts,,Is your data collected from publicly available sources with no incentive or directive to adversarially inflate the number of prompts?
#011,14,43.33,58.33,"Prompts focus on adversarial users (e.g., users are attempting to circumvent a guard model)","Clarify focus on adversarial benchmark (i.e., the benchmark is explicitly testing adversarial vulnerability) or broaden sampling beyond adversarial cases",,Do you publicly state that the benchmark focuses on adversial testing or does the benchmark design sample beyond adversarial cases?
#011,90,63.33,33.33,"Prompts focus on adversarial users (e.g., users are attempting to circumvent a guard model)",The benchmark does not present results for adversarial prompts or adversarial users are not applicable,,Does the benchmark avoid presenting results for adversarial prompts or scenarios where adversarial users are not applicable?
#012,65,60.00,33.33,"Prompt writers bias the sample to their own demographically-aligned word use, topics of interest, or other dimensions that tend to not explore the entirety of supported input space for the benchmark's supported use case",Record the demographics of the people generating prompts and selectively sample from less sampled populations,,Do you record the demographics of individuals generating prompts and make efforts to sample from underrepresented populations?
#012,71,73.33,45.83,"Prompt writers bias the sample to their own demographically-aligned word use, topics of interest, or other dimensions that tend to not explore the entirety of supported input space for the benchmark's supported use case",Source prompts from different geographic locales,,Do you source prompts from a range of different geographic regions to increase representativeness?
#014,17,70.00,29.17,Benchmark does not capture the distribution or variability of the task in the real world,"Source prompts from SUTs deployed in a real world for the task under evaluation for the benchmark (i.e., a non-experimental setting)",,"Do you source prompts from SUTs deployed in a real world setting for the task under evaluation within the benchmark (i.e., a non-experimental setting)?"
#014,143,53.33,29.17,Benchmark does not capture the distribution or variability of the task in the real world,Source additional prompts through peer review and/or submission from the broader community,,Do you source additional prompts through peer review and/or submissions from the broader community?
#014,144,80.00,33.33,Benchmark does not capture the distribution or variability of the task in the real world,Source prompts from SUTs deployed to real users under realistic laboratory circumstances,,"Do you source prompts from SUTs deployed to real users under realistic laboratory conditions (i.e., the user is directed to do a real task)?"
#014,193,70.00,41.67,Benchmark does not capture the distribution or variability of the task in the real world,Include domain experts in the construction of the benchmark with explicit directive to capture the full variability of the task,,Were domain experts involved in benchmark construction with the goal of capturing the full variability of the task?
#015,18,60.00,16.67,"Prompts have known properties allowing for achieving an unrealistic (i.e., non-generalizing) performance.  For example, prompts are of particular and known lengths.",Do not release representative sample prompts to SUT vendors,,Do you avoid releasing a representative sample of prompts to SUT developers?
#015,79,53.33,16.67,"Prompts have known properties allowing for achieving an unrealistic (i.e., non-generalizing) performance.  For example, prompts are of particular and known lengths.","Analyze prompt properties (e.g., length) and embedding space distribution visually",,Do you analyze prompt properties—such as length and embedding space distribution—using visual or statistical methods?
#015,80,53.33,16.67,"Prompts have known properties allowing for achieving an unrealistic (i.e., non-generalizing) performance.  For example, prompts are of particular and known lengths.",Source prompts from multiple people representing distinct populations,,Do you source prompts from multiple individuals representing distinct populations to ensure diversity and reduce bias?
#015,145,46.67,16.67,"Prompts have known properties allowing for achieving an unrealistic (i.e., non-generalizing) performance.  For example, prompts are of particular and known lengths.",Do not release the test set to SUT developers,,Do you avoid releasing the test set to SUT developers?
#015,201,66.67,37.50,"Prompts have known properties allowing for achieving an unrealistic (i.e., non-generalizing) performance.  For example, prompts are of particular and known lengths.","Are the prompt outputs multi-step, inherently high dimensional, or possess some other property making the benchmarked task difficult to game on the basis of a non-generalizing input feature (e.g., prompt lengths)?",,"Are the prompt outputs multi-step, inherently high dimensional, or possess some other property making the benchmarked task difficult to game on the basis of a non-generalizing input feature (e.g., prompt lengths)?"
#016,19,60.00,0.00,"An inadequate number of prompts are produced to identify rare critical events (i.e., tail risks)",Calibrate prompt count to statistical analysis,,Do you calibrate your prompt sample count to a statistical analysis indicating the number of samples required to identify the probability of rare events?
#016,146,23.33,50.00,"An inadequate number of prompts are produced to identify rare critical events (i.e., tail risks)","Establish in the task definition that rare events (i.e., tail risks) are not of interest to the benchmark relying person",,"Is it established in the task definition that rare events (i.e., tail risks) are not of interest to the benchmark-relying person?"
#018,21,16.67,54.17,"No coverage for target language idiomatic expressions (including differences in functional expression, less common APIs, etc., within programming languages) beyond those known to the benchmark authors",State limitation prominently within benchmark presentation for the language(s) supported by the benchmark,,Do you prominently and publicly state the benchmark does not cover idioms within the languages supported by the benchmark?
#018,147,93.33,37.50,"No coverage for target language idiomatic expressions (including differences in functional expression, less common APIs, etc., within programming languages) beyond those known to the benchmark authors",The benchmark does not process human languages in its inputs or outputs,,Does the benchmark avoid processing human languages in its inputs or outputs?
#018,166,60.00,29.17,"No coverage for target language idiomatic expressions (including differences in functional expression, less common APIs, etc., within programming languages) beyond those known to the benchmark authors",The task as defined seeks to avoid processing and expression of idioms,,Does the task definition aim to avoid processing and expression of idioms?
#018,179,53.33,25.00,"No coverage for target language idiomatic expressions (including differences in functional expression, less common APIs, etc., within programming languages) beyond those known to the benchmark authors","Source prompts from SUTs deployed in the real world for the task under evaluation for the benchmark (i.e., a non-experimental setting)",,"Are the source prompts taken from systems under test (SUTs) deployed in real-world, non-experimental settings for the task under evaluation?"
#018,180,60.00,33.33,"No coverage for target language idiomatic expressions (including differences in functional expression, less common APIs, etc., within programming languages) beyond those known to the benchmark authors",Source prompts from SUTs deployed in an experimental setting that allows for the collection of idioms,,Do you source prompts from experimental settings that enable the collection of idioms?
#019,22,56.67,20.83,"Cultural norms do not translate between cultural contexts (languages, geographies, etc.)","State limitation prominently within benchmark presentation, such as ""this is a work of __ culture, and as such definitions of violating content should be understood as representing that perspective""",,"Do you clearly state the cultural or contextual limitations of your benchmark, such as noting that definitions of violating content reflect a specific cultural perspective?"
#019,134,60.00,16.67,"Cultural norms do not translate between cultural contexts (languages, geographies, etc.)",The benchmark does not process human languages in its inputs or outputs,,Does the benchmark avoid processing human languages in its inputs and outputs?
#019,194,50.00,33.33,"Cultural norms do not translate between cultural contexts (languages, geographies, etc.)",Tag prompts with their cultural context and disclaim those contexts that are not covered,,Do you tag prompts with their cultural context and explicitly disclaim contexts that are not covered?
#020,23,70.00,37.50,Producing prompts in a language from prompts translated from another language introduces errors,Validate all machine-translated prompts with highly qualified speaker of both languages,,Do you validate all machine-translated prompts using a highly qualified speaker fluent in both source and target languages?
#020,63,40.00,45.83,Producing prompts in a language from prompts translated from another language introduces errors,Statistically validate translation quality and propagate uncertainty to the scores,,Do you statistically validate the quality of translations and propagate uncertainty into the benchmark scores?
#020,92,73.33,25.00,Producing prompts in a language from prompts translated from another language introduces errors,Benchmark authors do not use data vendors and commit to not using machine translation in generating the benchmark. All prompts originate in the language of the test.,,"Do you avoid using data vendors and machine translation in prompt generation, ensuring all prompts originate in the language of the test?"
#020,148,86.67,8.33,Producing prompts in a language from prompts translated from another language introduces errors,The benchmark does not test concepts related to language,,Does the benchmark avoid processing human languages in its inputs or outputs?
#020,181,86.67,16.67,Producing prompts in a language from prompts translated from another language introduces errors,Benchmark data is sourced entirely from a single language and makes no claims with respect to other languages,,"Is the benchmark data sourced entirely from a single language, and do you make no claims regarding its applicability to other languages?"
#020,185,83.33,16.67,Producing prompts in a language from prompts translated from another language introduces errors,"The data is all of naturalistic origin (e.g., it is collected from publicly available forums)",,"Is all the data of naturalistic origin (e.g., collected from public forums)?"
#020,195,60.00,12.50,Producing prompts in a language from prompts translated from another language introduces errors,Check whether translation back from the target language to the source language produces language consistent with the original language expression,,Do you check whether back-translating from the target language to the source language yields expressions consistent with the original language?
#021,24,100.00,12.50,Prompts are sent to model vendors when inferencing or all prompts are publicly available,(This mitigation may only be considered as applied when the prompts are never available to the SUT developer) Don't send prompts to SUT developers when inferencing,,(This mitigation may only be considered as applied when the prompts are never available to the SUT developer) Do you ensure that prompts are not shared with SUT developers during inferencing?
#021,25,73.33,20.83,Prompts are sent to model vendors when inferencing or all prompts are publicly available,(This mitigation may only be considered as applied when the prompts are only processed under contract) Contractually prohibit logging of test runs and human review of any test prompts,,(This mitigation may only be considered as applied when the prompts are only processed under contract) Do you include contractual prohibitions both against logging test runs and for allowing human review of test prompts?
#021,72,66.67,29.17,Prompts are sent to model vendors when inferencing or all prompts are publicly available,(This mitigation may only be considered as applied when this verification is affirmed with all SUT developer engineering staff) Verify with vendor engineering staff of SUT developers that prompts will not be recorded,,Do you verify with engineering staff of SUT developers that prompts will not be recorded? You may only consider this mitigation as applied when all relevant SUT engineering staffs affirm this.
#022,26,66.67,20.83,"Distribution of SUT inputs within the real world are substantially different in distribution from those within the benchmark (e.g., SUT users ask different questions from those posed by the benchmark authors)",Perform characteristic analysis of prompts collected from a production system versus prompts in the test set and publicly disclose variation,,"Do you perform a characteristic analysis comparing prompts collected from a production system to those in your test set, and do you publicly disclose any significant variations?"
#023,27,60.00,12.50,SUT developer trains against sample prompt set,Provide sample prompts under license that prohibits training,,Do you provide sample prompts under a license that explicitly prohibits their use in model training?
#023,91,53.33,25.00,SUT developer trains against sample prompt set,Include canary data in the prompt set whose inclusion in training would make the model testable for training against the benchmark,,"Do you include canary data in the prompt set that would reveal if the benchmark was used in model training, enabling detection of training contamination?"
#023,149,40.00,37.50,SUT developer trains against sample prompt set,"Require SUT developers to disclose their training practices in attempting to maximize their scores, including engineering the system to better address the sample set and/or train against the sample set directly and disclaim results when they have engineered (training or model design changes) to the sample set",,"Do you require SUT developers to disclose their training practices when attempting to maximize their scores, including any training or engineering done to specifically target the sample set? And do you require them to disclaim results in such cases?"
#024,53,70.00,25.00,"SUT is tested under conditions (e.g. temperature, iteration, context window settings) not matching deployment conditions or those conditions typically experienced by relying persons under default configurations",Require consistency between SUT temperature/options and default user-presented temperature/options or those clearly recommended in vendor published guidelines for use-case,,"Do you require that the system configuration (e.g., temperature, system prompts) used in benchmarking matches either the system’s default user-facing settings or those clearly recommended in vendor guidelines for the intended use case?"
#024,150,53.33,12.50,"SUT is tested under conditions (e.g. temperature, iteration, context window settings) not matching deployment conditions or those conditions typically experienced by relying persons under default configurations",Do not provide a sample set that allows for tuning the hyperparameters on the test set. This may only be selected if the evaluation set is not public.,,Do you avoid providing a sample set that would allow for tuning hyperparameters on the test set and do you avoid publishing the evaluation set?
#024,151,60.00,12.50,"SUT is tested under conditions (e.g. temperature, iteration, context window settings) not matching deployment conditions or those conditions typically experienced by relying persons under default configurations",Allow for a very limited number of evaluations for SUT developers,,Do you allow SUT developers a very limited number of evaluations?
#025,28,76.67,12.50,SUT developers place evaluator or other test ground truth within system chain,Do not make evaluator or ground truth publicly available,,Do you refrain from making the evaluator or ground truth publicly available?
#025,46,86.67,45.83,SUT developers place evaluator or other test ground truth within system chain,Use 100 percent human evaluators,,Do you use 100% human evaluators for assessing system performance?
#025,73,36.67,41.67,SUT developers place evaluator or other test ground truth within system chain,Employ backup evaluator with human validation of sampled outputs,,Do you employ a backup evaluator with human validation of sampled outputs to ensure evaluation reliability?
#025,93,86.67,41.67,SUT developers place evaluator or other test ground truth within system chain,Evaluator applies an algorithm to a list of correct answers and there is no legitimate reason to incorporate this into the system chain,,"Is the evaluator strictly algorithmic (i.e., applying a list of correct answers) with no legitimate reason to be embedded in the system-under-test (SUT) chain?"
#026,29,63.33,25.00,Evaluator (humans labeling the final outputs used in benchmarking or an LLM-as-a-judge) tuned on translated outputs with substantial errors,Validate all machine-translated prompts with highly qualified speaker of both languages,,Do you validate all machine-translated prompts using a highly qualified speaker fluent in both source and target languages?
#026,47,83.33,45.83,Evaluator (humans labeling the final outputs used in benchmarking or an LLM-as-a-judge) tuned on translated outputs with substantial errors,Use 100 percent human evaluators,,Do you use 100% human evaluators for assessing system performance?
#026,81,63.33,50.00,Evaluator (humans labeling the final outputs used in benchmarking or an LLM-as-a-judge) tuned on translated outputs with substantial errors,"For all languages benchmarked, validate evaluator vs native speaker response grading to ensure error rate consistent with representations to users",,"For all languages benchmarked, do you validate evaluator versus native speaker response grading to ensure the error rate is consistent with the representations made to users?"
#026,94,80.00,8.33,Evaluator (humans labeling the final outputs used in benchmarking or an LLM-as-a-judge) tuned on translated outputs with substantial errors,"Benchmark authors do not use data vendors (i.e., they can assert from direct observation of practices that the data used to tune the evaluator was not machine translated) and commit to not using machine translation in generating the benchmark",,"Can you confirm that no data vendors were used and that the evaluation data was not machine-translated, based on direct observation of practices?"
#026,152,86.67,37.50,Evaluator (humans labeling the final outputs used in benchmarking or an LLM-as-a-judge) tuned on translated outputs with substantial errors,"The benchmark does not test concepts related to language (i.e., the input and outputs are not textual)",,"Does the benchmark avoid testing concepts related to language (i.e., inputs and outputs are not textual)?"
#026,196,63.33,12.50,Evaluator (humans labeling the final outputs used in benchmarking or an LLM-as-a-judge) tuned on translated outputs with substantial errors,Check whether translation back from the target language to the source language produces language consistent with the original language expression,,Do you check whether back-translating from the target language to the source language yields expressions consistent with the original language?
#027,30,80.00,45.83,Low interrater reliability of ground truth data used to tune the evaluator,Measure and iterate on methods until (1) high interrater reliability is achieved between human labeling data used to train the evaluator model and (2) remaining uncertainty arising from disagreements is accounted for in the confidence measures presented to users,,"Do you measure and iterate on your methods until you achieve high interrater reliability for the human-labeled data used to train the evaluator, and ensure that any remaining uncertainty from disagreements is reflected in the confidence measures provided to users?"
#027,48,86.67,45.83,Low interrater reliability of ground truth data used to tune the evaluator,Use 100 percent human evaluators,,Do you use 100% human evaluators for assessing system performance?
#027,135,80.00,20.83,Low interrater reliability of ground truth data used to tune the evaluator,A high level of agreement between all human annotation outputs and the evaluation model is observed,,Is there evidence of high agreement between human annotation outputs and the evaluation model?
#027,137,80.00,0.00,Low interrater reliability of ground truth data used to tune the evaluator,Measure and iterate on methods until high interrater reliability is achieved,DUPLICATE OF 30?,Do you measure and iterate on methods until high interrater reliability is achieved?
#027,153,96.67,20.83,Low interrater reliability of ground truth data used to tune the evaluator,"Benchmark has singular answers that are checked from a list  (i.e., there is nothing for which evaluators may disagree)",,Does the benchmark use singular answers that are checked against a list?
#027,182,86.67,33.33,Low interrater reliability of ground truth data used to tune the evaluator,"Used an off-the-shelf evaluator model without tuning, but with an evaluation program that finds its reliability to be adequate for the evaluation task",,"Did you use an off-the-shelf evaluator model without tuning, while ensuring the evaluation program demonstrates adequate reliability for the task?"
#028,31,76.67,16.67,Evaluator tuned to SUT failing outputs and cannot generalize to new SUTs,Statistically confirm performance for every new SUT by checking the performance of the evaluator on a representative sample of SUT outputs,,Do you statistically confirm performance for each new system under test (SUT) by evaluating the benchmark's accuracy on a representative sample of that SUT's outputs?
#028,49,86.67,54.17,Evaluator tuned to SUT failing outputs and cannot generalize to new SUTs,Use 100 percent human evaluators,,Do you use 100% human evaluators for assessing system performance?
#028,95,83.33,45.83,Evaluator tuned to SUT failing outputs and cannot generalize to new SUTs,Evaluator applies an algorithm to check a list of correct answers to determine whether outputs are correct or compliant,,Does the evaluator apply an algorithm to compare model outputs against a list of correct answers to assess correctness or compliance?
#028,154,86.67,33.33,Evaluator tuned to SUT failing outputs and cannot generalize to new SUTs,"Benchmark has singular answers that are checked from a list (i.e., there is nothing for which evaluators may disagree)",,Does the benchmark use singular answers that are checked against a list?
#029,32,80.00,20.83,SUT developers produce training data from evaluator,Do not make evaluator or the answers publicly available,,Do you avoid making the evaluator or its answers publicly available?
#029,50,86.67,41.67,SUT developers produce training data from evaluator,Use 100 percent human evaluators,,Do you use 100% human evaluators for assessing system performance?
#029,96,60.00,45.83,SUT developers produce training data from evaluator,Evaluator applies an algorithm to check a list of correct answers to determine whether outputs are correct or compliant,,Does the evaluator apply an algorithm to compare model outputs against a list of correct answers to assess correctness or compliance?
#030,54,36.67,41.67,Certain SUTs produce outputs with higher evaluator errors than other SUTs,Run statistical analysis of evaluator failures and prominently disclose detected biases for all SUTs,,"Do you conduct statistical analysis of evaluator (human, model, or algorithm) failures and prominently disclose any detected biases across all SUTs?"
#030,97,83.33,50.00,Certain SUTs produce outputs with higher evaluator errors than other SUTs,"SUT is required to produce outputs conforming to the evaluator's expected format (e.g., true/false, multiple choice selection, executable code with unit tested conformance, etc.)",,"Is the system-under-test required to produce outputs that conform to the evaluator’s expected format (e.g., true/false, multiple choice)?"
#030,155,83.33,41.67,Certain SUTs produce outputs with higher evaluator errors than other SUTs,"Benchmark has singular answers (i.e., the outputs must be bit-exact in order to be correct) that are checked via a lookup table",,"Does the benchmark use singular answers (i.e., bit-exact outputs) that are checked via a lookup table?"
#031,55,73.33,45.83,Evaluator(s) perform poorly across all SUTs,Iteratively improve evaluator model and check performance until performance threshold is achieved,,Do you iteratively improve your evaluator model and validate its performance until it reaches a predefined performance threshold?
#031,98,76.67,37.50,Evaluator(s) perform poorly across all SUTs,"SUT is required to produce outputs conforming to the evaluator's expected format (e.g., true/false, multiple choice selection, executable code with unit tested conformance, etc.)",,"Is the system-under-test required to produce outputs that conform to the evaluator’s expected format (e.g., true/false, multiple choice)?"
#031,156,83.33,33.33,Evaluator(s) perform poorly across all SUTs,"Benchmark has singular answers (i.e., the outputs must be bit-exact in order to be correct) that are checked via a lookup table",,"Does the benchmark use singular answers (i.e., bit-exact outputs) that are checked via a lookup table?"
#032,58,26.67,58.33,Evaluator(s) have a high false reject rate (acceptable outputs rated as unacceptable),Use human evaluators on all outputs evaluated as unacceptable,,Do you use human evaluators for assessing system performance across all outputs evaluated by computational means when the outputs are evaluated as unacceptable?
#032,60,63.33,33.33,Evaluator(s) have a high false reject rate (acceptable outputs rated as unacceptable),Use 100 percent human evaluators,,Do you use 100% human evaluators for assessing system performance?
#032,99,73.33,8.33,Evaluator(s) have a high false reject rate (acceptable outputs rated as unacceptable),"SUT is required to produce outputs conforming to the evaluator's expected format (e.g., true/false, multiple choice selection, executable code with unit tested conformance, etc.)",,"Is the system-under-test required to produce outputs that conform to the evaluator’s expected format (e.g., true/false, multiple choice)?"
#032,138,80.00,45.83,Evaluator(s) have a high false reject rate (acceptable outputs rated as unacceptable),Evaluator is observed to reliably achieve a low false reject rate,,"Is the evaluator observed to reliably achieve a low false reject rate (e.g., compliant labeled as non-compliance)?"
#032,157,83.33,41.67,Evaluator(s) have a high false reject rate (acceptable outputs rated as unacceptable),"Benchmark has singular answers (i.e., the outputs must be bit-exact in order to be correct) that are checked via a lookup table",,"Does the benchmark use singular answers (i.e., bit-exact outputs) that are checked via a lookup table?"
#033,59,73.33,50.00,Evaluator(s) have a high false accept rate (unacceptable outputs rated as acceptable),Use human evaluators on all outputs evaluated as acceptable,,Do you use human evaluators for assessing system performance across all outputs evaluated by computational means when the outputs are evaluated as acceptable?
#033,61,66.67,33.33,Evaluator(s) have a high false accept rate (unacceptable outputs rated as acceptable),Use 100 percent human evaluators,,Do you use 100% human evaluators for assessing system performance?
#033,100,73.33,33.33,Evaluator(s) have a high false accept rate (unacceptable outputs rated as acceptable),"SUT is required to produce outputs conforming to the evaluator's expected format (e.g., true/false, multiple choice selection, executable code with unit tested conformance, etc.)",,"Is the system-under-test required to produce outputs that conform to the evaluator’s expected format (e.g., true/false, multiple choice)?"
#033,139,80.00,50.00,Evaluator(s) have a high false accept rate (unacceptable outputs rated as acceptable), Evaluator is observed to reliably achieve a low false accept rate,,"Is the evaluator observed to reliably achieve a low false accept rate (e.g., non-compliant labeled as compliance)?"
#033,158,80.00,37.50,Evaluator(s) have a high false accept rate (unacceptable outputs rated as acceptable),"Benchmark has singular answers (i.e., the outputs must be bit-exact in order to be correct) that are checked via a lookup table",,"Does the benchmark use singular answers (i.e., bit-exact outputs) that are checked via a lookup table?"
#034,33,80.00,37.50,Inadequate sample size for identifying performance,Calibrate prompt count to statistical analysis or produce sufficient prompts that the measure will clearly be consistent,,"Do you calibrate the number of prompts used according to statistical analysis, or otherwise ensure that the sample count is sufficient to produce consistent and reliable measures?"
#035,34,70.00,58.33,Failure to propagate uncertainty or confidence from lower level measures to higher level grades,Prominently display uncertainty estimates in composition with the benchmark results,,Do you prominently display uncertainty estimates alongside your benchmark results?
#035,51,70.00,33.33,Failure to propagate uncertainty or confidence from lower level measures to higher level grades,Callout qualities of prompt subpopulations for scores that are systematically worse,,Do you identify and call out specific qualities of prompt subpopulations where SUT performance is systematically worse?
#035,159,66.67,58.33,Failure to propagate uncertainty or confidence from lower level measures to higher level grades,Property of interest is appropriately measured without any aggregation among different subpopulations,,Is the property of interest appropriately measurable without aggregating across different subpopulations?
#036,35,90.00,37.50,Presentation without uncertainty or confidence of the scores,Prominently display uncertainty estimates in composition with the benchmark results,,Do you prominently display uncertainty estimates alongside your benchmark results?
#036,200,63.33,41.67,Presentation without uncertainty or confidence of the scores,Benchmark provides guidance or reference for the display or accompanying statistics to inform users of benchmark uncertainty,,Does the benchmark provide guidance or references on how to display or interpret statistics that communicate benchmark uncertainty?
#037,36,70.00,0.00,User does not read disclaimers,Prominently display disclaimers everywhere benchmarks are presented,,Do you prominently display disclaimers wherever the benchmark is presented?
#037,56,76.67,33.33,User does not read disclaimers,Iteratively improve display of disclaimers via UX methods until users can express knowledge of the limitations,,Do you iteratively improve how disclaimers are displayed via UX research until users demonstrate understanding of the benchmark's limitations?
#038,37,76.67,4.17,User does not understand visual representation of scores,Perform user evaluation with target user group and iterate design,,Do you conduct user evaluations with your target user group and iterate on the benchmark design based on their feedback?
#038,75,66.67,4.17,User does not understand visual representation of scores,Perform design studies with potential users to understand presentation requirements,,Do you perform design studies with potential users to understand presentation requirements for benchmark outputs?
#038,160,76.67,4.17,User does not understand visual representation of scores,Limit presentation and audience to sophisticated persons that can be assumed to understand the visual representation,,Do you limit the presentation and audience to sophisticated users who can be assumed to understand visual representations?
#038,197,63.33,29.17,User does not understand visual representation of scores,Implement Interactive Tutorials or Help Sections to provide users with accessible guides explaining the visual representations used in the benchmarks.,,Have you implemented interactive tutorials or help sections that explain the visual representations used in the benchmarks?
#039,38,73.33,0.00,User misunderstands the scope of the benchmark,Prominently display the scope of the benchmark in terms of what the user should or should not rely on,,"Do you clearly and prominently display the scope of the benchmark, including guidance on what users should or should not rely on it for?"
#039,122,63.33,20.83,User misunderstands the scope of the benchmark,Maintained feedback channel for benchmark users is available,,"Is there an ongoing, maintained feedback channel available for benchmark users?"
#039,123,60.00,12.50,User misunderstands the scope of the benchmark,Contact person is listed indicating that person will be responsive to inquiries,,"Is a contact person listed for the benchmark, and is that person responsive to inquiries?"
#040,66,76.67,12.50,"Different demographic groups (cultural, professional, educational, etc.) viewing the benchmark have different interpretations of the information conveyed",Localize the presentation in consultation with people who have a deep understanding of the interpretation of benchmark information within a demographic group,,Do you localize the presentation of benchmark results in consultation with individuals who have deep understanding of how such information is interpreted within specific demographic groups?
#040,82,73.33,29.17,"Different demographic groups (cultural, professional, educational, etc.) viewing the benchmark have different interpretations of the information conveyed",Direct the benchmark to a professional audience with layers of supporting information for experts,,"Do you direct the benchmark to a professional audience, providing layers of supporting information suitable for expert review?"
#040,83,80.00,25.00,"Different demographic groups (cultural, professional, educational, etc.) viewing the benchmark have different interpretations of the information conveyed",Publicly disclaim the benchmark as a tool for consumers,,Do you publicly disclaim the benchmark as a tool intended for consumer use?
#040,88,73.33,20.83,"Different demographic groups (cultural, professional, educational, etc.) viewing the benchmark have different interpretations of the information conveyed",Limit promotion of the benchmark to persons sophisticated for the task being benchmarked and its measurement,,Do you limit promotion of the benchmark to individuals with a sophisticated understanding of the task being benchmarked and its measurement implications?
#040,127,73.33,0.00,"Different demographic groups (cultural, professional, educational, etc.) viewing the benchmark have different interpretations of the information conveyed",Assumptions of normative properties (how people should be interpreting the benchmark according to specific cultures or contexts) are documented,,"Are any assumptions about normative properties (e.g., how the benchmark should be interpreted within specific cultures or contexts) clearly documented?"
#041,39,73.33,0.00,SUT developer tunes safety program to benchmark sample set,Signed agreements with SUT developers prohibit tuning with the sample set,,Do you have signed agreements with SUT developers that prohibit tuning systems using the provided sample set?
#041,57,96.67,0.00,SUT developer tunes safety program to benchmark sample set,Do not provide a benchmark sample set,,"Do you intentionally avoid providing a representative sample set (i.e., a dataset illustrative of the characteristics of the prompts included within the test set)?"
#041,76,56.67,0.00,SUT developer tunes safety program to benchmark sample set,License prohibits tuning to the sample set (sample set may be available without a signed agreement),,Does your license prohibit tuning to the sample set?
#042,42,80.00,0.00,SUT developer trains SUT against sample set,Do not provide a representative sample set,,"Do you intentionally avoid providing a representative sample set (i.e., a dataset illustrative of the characteristics of the prompts included within the test set)?"
#042,77,70.00,0.00,SUT developer trains SUT against sample set,Signed agreements with SUT developers prohibit training with the sample set,,Do you have signed agreements with SUT developers that explicitly prohibit training with the sample set?
#042,78,56.67,0.00,SUT developer trains SUT against sample set,License prohibits training to the sample set (sample set may be available without a signed agreement),,Does your license prohibit tuning to the sample set?
#043,44,36.67,45.83,User behavior shifts through time,Actively update the tests in response to changing user behaviors,,Do you actively update your tests in response to changing user behaviors?
#044,43,70.00,0.00,Test set leaks out to the general internet,Do not provide the test set,,Do you intentionally avoid providing the test set publicly or to SUT developers?
#044,45,33.33,33.33,Test set leaks out to the general internet,Actively monitor the internet for test set samples,,Do you actively monitor the internet to check whether any test set samples have appeared online?
#044,74,40.00,33.33,Test set leaks out to the general internet,Periodically introduce new test set prompts and monitor for statistical differences in performance across new and old items,,Do you periodically introduce new test set prompts and monitor for statistical differences in performance between new and old items?
#045,52,56.67,33.33,SUT developers update the SUT without changing the name or version of the SUT,(Only for 3rd party benchmarking) Periodically re-test all SUTs,,Do you periodically re-test all systems under test (SUTs) to maintain up-to-date comparisons?
#045,161,66.67,33.33,SUT developers update the SUT without changing the name or version of the SUT,Only test SUTs with well known version identifiers,,Do you only test SUTs with well-known version identifiers?
#046,67,73.33,0.00,SUT developers can run the benchmark an unlimited number of times,Do not allow evaluation on demand. ,,Do you restrict or avoid evaluation on demand to preserve benchmark integrity?
#047,103,70.00,29.17,The benchmark does not measure a property of the SUT linked to the user task,How tested capability or concept translates to benchmarked task is described,,Do you describe how the tested capability or concept is translated into the benchmarked task?
#047,104,76.67,0.00,The benchmark does not measure a property of the SUT linked to the user task,Domain experts are involved in the production of the benchmark,,Are domain experts involved in the creation of the benchmark?
#047,105,60.00,0.00,The benchmark does not measure a property of the SUT linked to the user task,Domain literature is integrated,,Do you integrate relevant domain literature into the benchmark?
#048,107,56.67,4.17,Users cannot map the scores to a mental model of likely SUT behavior in the real world,Metric floors and ceilings are included,,Are metric floors and ceilings included as part of the benchmark methodology?
#048,108,60.00,8.33,Users cannot map the scores to a mental model of likely SUT behavior in the real world,Human performance level is included,,Is a human performance level incorporated into the benchmark?
#048,109,56.67,4.17,Users cannot map the scores to a mental model of likely SUT behavior in the real world,Random decision/output performance level is included,,Is a performance level for random decision/output also provided in the benchmark?
#049,110,63.33,12.50,SUT developer trains against evaluation set,Globally unique identifier or encryption of evaluation instances is added,,Do you add a globally unique identifier or apply encryption to evaluation instances?
#049,112,90.00,0.00,SUT developer trains against evaluation set,Do not provide the evaluation set,,Do you refrain from providing the evaluation set to prevent potential misuse?
#049,113,70.00,0.00,SUT developer trains against evaluation set,Signed agreements with SUT developers prohibit training with the sample set,,Are there signed agreements with SUT developers that prohibit using the sample set for training?
#049,114,50.00,4.17,SUT developer trains against evaluation set,License prohibits training to the sample set (sample set may be available without a signed agreement),,"Does the license explicitly prohibit using the sample set for training, even if the sample set is available without a signed agreement?"
#049,118,50.00,25.00,SUT developer trains against evaluation set,Include canary data in the prompt set whose inclusion in training would make the model testable for training against the benchmark,,Do you include canary data in the prompt set such that its inclusion in training would enable testing whether the model has been trained on the benchmark?
#050,111,53.33,0.00,SUT developer trains against evaluation set,Globally unique identifier or encryption of evaluation instances is added,,Do you add a globally unique identifier or apply encryption to evaluation instances?
#050,115,90.00,12.50,SUT developer trains against evaluation set,Do not provide the evaluation set,,Do you refrain from providing the evaluation set?
#050,116,53.33,20.83,SUT developer trains against evaluation set,Signed agreements with SUT developers prohibit training with the evaluation set,,Are there signed agreements with SUT developers that specifically prohibit training with the evaluation set?
#050,117,56.67,16.67,SUT developer trains against evaluation set,License prohibits training to the evaluation set (evaluation set may be available without a signed agreement),,"Does the license explicitly prohibit training with the evaluation set, even when it might be available without a signed agreement?"
#050,119,63.33,25.00,SUT developer trains against evaluation set,Include canary data in the prompt set whose inclusion in training would make the model testable for training against the benchmark,,Do you include canary data in the prompt set such that its inclusion in training would enable testing whether the model has been trained on the benchmark?
#051,120,50.00,4.17,SUT developers are not bound to adhere to benchmark integrity requirements,"Release requirements (i.e., the practices and norms that must be followed by the SUT developer) are specified publicly",,Are the release requirements such as the practices and norms required to be followed by the SUT developer specified publicly?
#051,121,80.00,8.33,SUT developers are not bound to adhere to benchmark integrity requirements,SUT developers are legally and financially liable for harms produced through inappropriate reliability arising from SUT developers violating the release requirements,,"Are SUT developers held legally and financially accountable for harms that might arise from violating benchmark release requirements (i.e., if training practices producing a benchmark score not representative of SUT performance in the real world)?"
#052,124,43.33,4.17,Benchmark production failed to account for an idiosyncratic failure mode,Accompanying paper is accepted at peer-reviewed venue and/or a preprint version of the paper is highly cited,,"Has the accompanying paper been accepted at a peer-reviewed venue, or is there a preprint version that is highly cited?"
#052,125,63.33,4.17,Benchmark production failed to account for an idiosyncratic failure mode,Benchmark design process is documented,,Is the benchmark design process documented?
#052,126,63.33,4.17,Benchmark production failed to account for an idiosyncratic failure mode,Test tasks & rationale are documented,,Are the test tasks and the rationale behind them documented?
#052,128,63.33,4.17,Benchmark production failed to account for an idiosyncratic failure mode,"Test environment design or prompt design process (i.e., how the prompts are written and by whom) is documented",,"Is the design process for the test environment or prompts (e.g., how prompts are written and by whom) documented?"
#052,129,56.67,4.17,Benchmark production failed to account for an idiosyncratic failure mode,Data sources and data collection process are explained,,Are the data sources and the data collection process explained?
#052,130,50.00,4.17,Benchmark production failed to account for an idiosyncratic failure mode,Data preprocessing steps are described (if applicable),,Are any data preprocessing steps described or found to be non-relevant to benchmark users?
#052,131,50.00,4.17,Benchmark production failed to account for an idiosyncratic failure mode,Data annotation process is described (if applicable),,Are any data annotation steps described or found to be non-relevant to benchmark users?
#052,132,50.00,4.17,Benchmark production failed to account for an idiosyncratic failure mode,Evaluation metric is documented,,Is the evaluation metric used by the benchmark clearly documented?
#053,133,63.33,0.00,Linkage between the evaluation prompts and the information the prompts are meant to supply via the benchmark is not well understood by the benchmark user,"Data representativeness is explained (if applicable). For example, demographics of crowd workers are collected and reported.",,"Is the representativeness of the data explained (e.g., are the demographics of crowd workers collected and reported)?"
#054,136,73.33,8.33,New requirements emerge that would reasonably be interpreted as being covered in the task definition,"Periodically review the SUT task, update to match user expectations, update existing prompts, source new prompts to ensure coverage, and create a new versioned release of the benchmark",,"Is the benchmark periodically reviewed to ensure the SUT task aligns with current user expectations, including updating prompts, sourcing new ones for better coverage, and releasing versioned updates?"
#055,167,73.33,8.33,"A SUT developer has disparate access to information about the benchmark after its release (i.e., information not provided to other SUT developers)","Publish and maintain benchmark within an organization that does not publish SUTs (i.e., the benchmark is ""third party"" with respect to all benchmarked systems)",,"Do you publish the benchmark at an organization that does not develop SUTs (i.e., is it a third-party benchmark)?"
#055,168,63.33,8.33,"A SUT developer has disparate access to information about the benchmark after its release (i.e., information not provided to other SUT developers)",Require all benchmark authors and prompt writers to maintain confidentiality of non-public information,,Do you require all benchmark authors and prompt writers to maintain confidentiality of non-public information regarding the benchmark?
#055,169,56.67,12.50,"A SUT developer has disparate access to information about the benchmark after its release (i.e., information not provided to other SUT developers)",Prohibit benchmark authors from optimizing SUTs for the benchmark,,Do you prohibit benchmark authors from optimizing SUTs for the benchmark?
#055,170,66.67,12.50,"A SUT developer has disparate access to information about the benchmark after its release (i.e., information not provided to other SUT developers)",Maintain an information barrier protocol within the organization producing the benchmark between the benchmark authors/prompt writer and the SUT developers active within the same organization. This is sometimes referred to as a Chinese wall or an ethics wall. ,,"Is your organization a SUT developer and do you maintain an information barrier protocol (e.g., Chinese wall) between benchmark authors/prompt writers and SUT developers within the same organization?"
#056,171,70.00,12.50,The benchmark authors do not know how to formulate the problem as prompts that are illustrative to the user relying on the benchmark,Involve domain experts in the definition of the task and prompts,,Do you involve domain experts in defining the task and prompts?
#057,172,66.67,20.83,Benchmark authors do not know how to propagate statistical uncertainty into a user presentation,A benchmark author has formal training in statistical methods,,Does at least one benchmark author have formal training in statistical methods?
#058,173,36.67,37.50,"Understanding the benchmark requires more resources (e.g., study, expertise, exploration) than the relying user has time to expend",Comparisons to well known benchmarks are provided indicating what is the same and what is different,,Do you provide comparisons to well-known benchmarks that indicate what is the same and what is different?
#058,174,43.33,33.33,"Understanding the benchmark requires more resources (e.g., study, expertise, exploration) than the relying user has time to expend",A FAQ is published with the benchmark,,Do you publish a FAQ along with the benchmark?
#058,175,36.67,45.83,"Understanding the benchmark requires more resources (e.g., study, expertise, exploration) than the relying user has time to expend",Simple interpretative statements for scores are provided in the user interface,,Do you provide simple interpretative statements for scores in the user interface?
#058,176,43.33,41.67,"Understanding the benchmark requires more resources (e.g., study, expertise, exploration) than the relying user has time to expend",The task is simplified until it requires less mental effort to understand,,Have you simplified the task to reduce the mental effort required to understand it?
#058,177,40.00,41.67,"Understanding the benchmark requires more resources (e.g., study, expertise, exploration) than the relying user has time to expend",Example prompts for the task are provided,,Do you include example prompts for the task?
#031,202,0.00,0.00,Evaluator(s) perform poorly across all SUTs,"Used an off-the-shelf evaluator model without tuning, but with an evaluation program that finds its reliability to be adequate for the evaluation task",,"Did you use an off-the-shelf evaluator model without tuning, but with an evaluation program that finds its reliability to be adequate for the evaluation task?"