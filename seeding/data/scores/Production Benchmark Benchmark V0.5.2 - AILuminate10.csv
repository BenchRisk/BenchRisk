Threat ID,Stage,Category,Threat to Reliability,Severity,Mitigated Risk,Underperformance,Benchmark Scored,Available Mitigations,Adopted Mitigation(s),Affirming Status,Affirming Date,References and Notes
#001,(1) Task Definition,Intelligibility,The information provided by the benchmark does not match with the information the benchmark user believes is provided,1.0,0.0,0.0,91.32,"1,106,186,198","1,106",,6/1/2025,
#002,(1) Task Definition,Comprehensiveness,The task is defined too broadly to achieve any reasonable degree of coverage over the use case,0.9,0.9,0.9,0,"64,68,162,187,188,189,190,191",,,6/1/2025,
#003,(2) Prompt Generation,Correctness,Input prompt writers produce prompts with LLMs,0.5,0.0,0.0,47.28395062,"2,3,4,70,89,163,192,199","3,70",,6/1/2025,
#004,(2) Prompt Generation,Correctness,Prompts are collected from publicly available sources that are also likely to be in the datasets of SUT developers,0.9,0.1,0.1,80.84166667,"5,6,140",5,,6/1/2025,
#005,(2) Prompt Generation,Correctness,Data vendor licenses private data that is available to other parties,0.5,0.0,0.0,50.685,"7,8,101","7,8",,6/1/2025,
#006,(2) Prompt Generation,Correctness,Data vendor provides same prompts to multiple organizations including benchmark authors and SUT developers,0.8,0.2,0.2,58.33333333,"9,102,141",9,,6/1/2025,
#007,(2) Prompt Generation,Comprehensiveness,"Singular prompts without a distributional tie lack a capacity for detecting distributional failings, harms, or impacts",0.6,0.1,0.1,48.8,"10,62",10,,6/1/2025,
#008,(2) Prompt Generation,Correctness,"Prompt writers produce prompts with inadequate variability within the valid input space (e.g., a single prompt writer writes all the prompts)",0.5,0.0,0.0,49.75333333,"11,69,142,164","11,69",,6/1/2025,
#009,(2) Prompt Generation,Comprehensiveness,Adversarial prompt bulking (increasing the number of prompts by multiplying them by the number of tactics),0.6,0.1,0.1,55.09580247,"12,84,86,165,178,183","84,86",,6/1/2025,
#010,(2) Prompt Generation,Comprehensiveness,Prompt perturbation bulking (increasing the number of prompts by making small changes to root prompts),0.6,0.1,0.1,54.19892361,"13,85,87,184","85,87",,6/1/2025,
#011,(2) Prompt Generation,Comprehensiveness,"Prompts focus on adversarial users (e.g., users are attempting to circumvent a guard model)",0.6,0.2,0.1,48.88888889,"14,90",14,,6/1/2025,
#012,(2) Prompt Generation,Comprehensiveness,"Prompt writers bias the sample to their own demographically-aligned word use, topics of interest, or other dimensions that tend to not explore the entirety of supported input space for the benchmark's supported use case",0.6,0.1,0.1,52.18888889,"65,71",71,,6/1/2025,
#014,(2) Prompt Generation,Comprehensiveness,Benchmark does not capture the distribution or variability of the task in the real world,0.6,0.6,0.6,0,"17,143,144,193",,,6/1/2025,
#015,(2) Prompt Generation,Longevity,"Prompts have known properties allowing for achieving an unrealistic (i.e., non-generalizing) performance.  For example, prompts are of particular and known lengths.",0.7,0.1,0.1,60.26234568,"18,79,80,145,201","79,80",,6/1/2025,
#016,(2) Prompt Generation,Consistency,"An inadequate number of prompts are produced to identify rare critical events (i.e., tail risks)",0.7,0.3,0.2,40.8,"19,146",19,,6/1/2025,
#018,(2) Prompt Generation,Comprehensiveness,"No coverage for target language idiomatic expressions (including differences in functional expression, less common APIs, etc., within programming languages) beyond those known to the benchmark authors",0.6,0.2,0.2,35.22916667,"21,147,166,179,180",21,,6/1/2025,
#019,(2) Prompt Generation,Comprehensiveness,"Cultural norms do not translate between cultural contexts (languages, geographies, etc.)",0.6,0.6,0.5,0,"22,134,194",,,6/1/2025,
#020,(2) Prompt Generation,Correctness,Producing prompts in a language from prompts translated from another language introduces errors,0.6,0.6,0.6,0,"23,63,92,148,181,185,195",,92,6/1/2025,
#021,(3) Prompt Inferencing,Longevity,Prompts are sent to model vendors when inferencing or all prompts are publicly available,0.9,0.2,0.2,71.04166667,"24,25,72",72,,6/1/2025,
#022,(3) Prompt Inferencing,Correctness,"Distribution of SUT inputs within the real world are substantially different in distribution from those within the benchmark (e.g., SUT users ask different questions from those posed by the benchmark authors)",0.6,0.6,0.5,0,26,,,6/1/2025,
#023,(3) Prompt Inferencing,Correctness,SUT developer trains against sample prompt set,0.9,0.3,0.3,55.9,"27,91,149",27,,6/1/2025,
#024,(3) Prompt Inferencing,Intelligibility,"SUT is tested under conditions (e.g. temperature, iteration, context window settings) not matching deployment conditions or those conditions typically experienced by relying persons under default configurations",0.6,0.1,0.1,49.6,"53,150,151",53,,6/1/2025,
#025,(4) Output Evaluation,Correctness,SUT developers place evaluator or other test ground truth within system chain,0.9,0.1,0.1,85.98517361,"28,46,73,93","28,73",,6/1/2025,
#026,(4) Output Evaluation,Correctness,Evaluator (humans labeling the final outputs used in benchmarking or an LLM-as-a-judge) tuned on translated outputs with substantial errors,0.8,0.1,0.1,61.25,"29,47,81,94,152,196",81,,6/1/2025,
#027,(4) Output Evaluation,Consistency,Low interrater reliability of ground truth data used to tune the evaluator,0.6,0.1,0.1,54.39166667,"30,48,135,137,153,182",30,,6/1/2025,
#028,(4) Output Evaluation,Correctness,Evaluator tuned to SUT failing outputs and cannot generalize to new SUTs,0.6,0.1,0.1,49.13888889,"31,49,95,154",31,,6/1/2025,
#029,(4) Output Evaluation,Correctness,SUT developers produce training data from evaluator,0.8,0.1,0.1,66.49166667,"32,50,96",32,,6/1/2025,
#030,(4) Output Evaluation,Correctness,Certain SUTs produce outputs with higher evaluator errors than other SUTs,0.6,0.2,0.2,35.94166667,"54,97,155",54,,6/1/2025,
#031,(4) Output Evaluation,Consistency,Evaluator(s) perform poorly across all SUTs,0.8,0.1,0.1,70.15555556,"55,98,156,202",55,,6/1/2025,
#032,(4) Output Evaluation,Correctness,Evaluator(s) have a high false reject rate (acceptable outputs rated as unacceptable),0.9,0.1,0.1,79.35833333,"58,60,99,138,157",138,,6/1/2025,
#033,(4) Output Evaluation,Correctness,Evaluator(s) have a high false accept rate (unacceptable outputs rated as acceptable),0.8,0.1,0.1,73.8,"59,61,100,139,158",139,,6/1/2025,
#034,(5) Scoring,Consistency,Inadequate sample size for identifying performance,0.7,0.1,0.0,62.125,33,33,,6/1/2025,
#035,(5) Scoring,Intelligibility,Failure to propagate uncertainty or confidence from lower level measures to higher level grades,0.5,0.1,0.1,43.75,"34,51,159",34,,6/1/2025,
#036,(6) Grade Presentation,Intelligibility,Presentation without uncertainty or confidence of the scores,0.8,0.0,0.0,70.3125,"35,200",35,,6/1/2025,
#037,(6) Grade Presentation,Intelligibility,User does not read disclaimers,0.5,0.2,0.1,35,"36,56",36,,6/1/2025,
#038,(6) Grade Presentation,Intelligibility,User does not understand visual representation of scores,0.6,0.0,0.0,56.64268904,"37,75,160,197","75,160",,6/1/2025,
#039,(6) Grade Presentation,Intelligibility,User misunderstands the scope of the benchmark,0.7,0.0,0.0,69.07642593,"38,122,123","38,122,123",,6/1/2025,
#040,(6) Grade Presentation,Intelligibility,"Different demographic groups (cultural, professional, educational, etc.) viewing the benchmark have different interpretations of the information conveyed",0.5,0.0,0.0,51.84666667,"66,82,83,88,127","82,88",,6/1/2025,
#041,(7) Upkeep,Longevity,SUT developer tunes safety program to benchmark sample set,0.7,0.3,0.3,38.53333333,"39,57,76",76,,6/1/2025,
#042,(7) Upkeep,Longevity,SUT developer trains SUT against sample set,0.8,0.3,0.3,44.76666667,"42,77,78",78,,6/1/2025,
#043,(7) Upkeep,Longevity,User behavior shifts through time,0.5,0.2,0.0,35.475,44,44,,6/1/2025,
#044,(7) Upkeep,Longevity,Test set leaks out to the general internet,0.9,0.1,0.1,75.68,"43,45,74","43,74",,6/1/2025,
#045,(7) Upkeep,Longevity,SUT developers update the SUT without changing the name or version of the SUT,0.6,0.0,0.0,57.08395062,"52,161","52,161",,6/1/2025,
#046,(3) Prompt Inferencing,Longevity,SUT developers can run the benchmark an unlimited number of times,0.8,0.2,0.0,55,67,67,,6/1/2025,
#047,(1) Task Definition,Intelligibility,The benchmark does not measure a property of the SUT linked to the user task,0.7,0.0,0.0,66.65133333,"103,104,105","103,104,105",,6/1/2025,
#048,(6) Grade Presentation,Intelligibility,Users cannot map the scores to a mental model of likely SUT behavior in the real world,0.5,0.2,0.2,31.575,"107,108,109",107,,6/1/2025,
#049,(3) Prompt Inferencing,Correctness,SUT developer trains against evaluation set,0.9,0.0,0.0,84.73541667,"110,112,113,114,118","112,114",,6/1/2025,
#050,(7) Upkeep,Longevity,SUT developer trains against evaluation set,0.9,0.1,0.1,81.2125,"111,115,116,117,119",115,,6/1/2025,
#051,(7) Upkeep,Longevity,SUT developers are not bound to adhere to benchmark integrity requirements,0.7,0.3,0.3,36.97916667,"120,121",120,,6/1/2025,
#052,(1) Task Definition,Correctness,Benchmark production failed to account for an idiosyncratic failure mode,0.6,0.0,0.0,60.93433459,"124,125,126,128,129,130,131,132","124,125,126,128,129,130,131,132",,6/1/2025,
#053,(2) Prompt Generation,Intelligibility,Linkage between the evaluation prompts and the information the prompts are meant to supply via the benchmark is not well understood by the benchmark user,0.5,0.2,0.0,31.66666667,133,133,,6/1/2025,
#054,(7) Upkeep,Longevity,New requirements emerge that would reasonably be interpreted as being covered in the task definition,0.5,0.1,0.0,34.75555556,136,136,,6/1/2025,