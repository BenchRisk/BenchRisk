---
number: 9
dateAdded: '2025-04-01'
dateUpdated: '2025-04-01'
short: Adversarial prompt bulking (increasing the number of prompts by multiplying
  them by the number of tactics)
example: A benchmark designed to evaluate model robustness against jailbreaks creates
  100 base adversarial prompts and then applies 10 paraphrasing or obfuscation tactics
  to each, resulting in 1,000 prompts. While this gives the appearance of broad coverage,
  the underlying semantic space is still narrowâ€”centered on just 100 scenarios. A
  model that learns to defend against these specific base prompts or common surface
  patterns scores highly, even though it remains vulnerable to novel or semantically
  different jailbreaks. A benchmark user assumes the model is robust and deploys it
  in a moderation tool, which is quickly circumvented by attacks not represented in
  the bloated prompt set.
severity: 0.6
stage: (2) Prompt Generation
dimension: Comprehensiveness
about: todo
---

todo