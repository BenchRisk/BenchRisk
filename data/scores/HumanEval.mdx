---
name: HumanEval
adoptedMitigations:
  - 1
  - 68
  - 89
  - 70
  - 140
  - 5
  - 101
  - 141
  - 102
  - 10
  - 12
  - 165
  - 13
  - 90
  - 19
  - 92
  - 93
  - 94
  - 153
  - 154
  - 95
  - 96
  - 97
  - 98
  - 138
  - 99
  - 139
  - 100
  - 33
  - 160
  - 88
  - 82
  - 161
  - 104
  - 105
  - 103
  - 107
  - 128
  - 129
  - 131
  - 132
  - 124
  - 125
  - 126
absentMitigations:
  - 186
  - 198
  - 106
  - 64
  - 162
  - 187
  - 188
  - 189
  - 190
  - 191
  - 192
  - 2
  - 3
  - 4
  - 163
  - 199
  - 6
  - 8
  - 7
  - 9
  - 62
  - 11
  - 164
  - 69
  - 142
  - 178
  - 84
  - 86
  - 183
  - 184
  - 85
  - 87
  - 14
  - 65
  - 71
  - 144
  - 17
  - 193
  - 143
  - 80
  - 145
  - 18
  - 201
  - 79
  - 146
  - 179
  - 147
  - 180
  - 166
  - 21
  - 194
  - 134
  - 22
  - 195
  - 148
  - 181
  - 23
  - 185
  - 63
  - 24
  - 25
  - 72
  - 26
  - 27
  - 91
  - 149
  - 53
  - 150
  - 151
  - 73
  - 28
  - 46
  - 196
  - 47
  - 81
  - 152
  - 29
  - 135
  - 137
  - 48
  - 182
  - 30
  - 49
  - 31
  - 32
  - 50
  - 155
  - 54
  - 202
  - 156
  - 55
  - 58
  - 60
  - 157
  - 59
  - 61
  - 158
  - 34
  - 51
  - 159
  - 200
  - 35
  - 56
  - 36
  - 37
  - 75
  - 197
  - 122
  - 123
  - 38
  - 66
  - 83
  - 127
  - 57
  - 76
  - 39
  - 42
  - 77
  - 78
  - 44
  - 74
  - 43
  - 45
  - 52
  - 67
  - 108
  - 109
  - 112
  - 113
  - 114
  - 118
  - 110
  - 115
  - 116
  - 117
  - 119
  - 111
  - 120
  - 121
  - 130
  - 133
  - 136
benchmarkDescription: Benchmark indicates how well the system under test can support a human writing python code by specifying docstrings whose function bodies are completed by the system.
dateScored: '2025-04-01'
reference: https://arxiv.org/abs/2107.03374
---

Evaluating Large Language Models Trained on Code

> We introduce Codex, a GPT language model fine-tuned on publicly available code from GitHub, and study its Python code-writing capabilities. A distinct production version of Codex powers GitHub Copilot. On HumanEval, a new evaluation set we release to measure functional correctness for synthesizing programs from docstrings, our model solves 28.8% of the problems, while GPT-3 solves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts. Using this method, we solve 70.2% of our problems with 100 samples per problem. Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables. Finally, we discuss the potential broader impacts of deploying powerful code generation technologies, covering safety, security, and economics.
