---
title: "Lessons for Editors of AI Incidents from the AI Incident Database"
venue: The Thirty-Seventh Annual Conference on Innovative Applications of Artificial Intelligence (IAAI-25)
authors: Paeth, K., Atherton, D., Pittaras, N., Frase, H., McGregor, S.
citation: "Paeth, K., et al.(2025). Lessons for Editors of AI Incidents from the AI Incident Database. In Proceedings of the Thirty-Seventh Annual Conference on Innovative Applications of Artificial Intelligence (IAAI-25). Philadelphia."
bibtex: "@inproceedings{Paeth25,address = {Philadelphia, Pennsylvania}, author = {Paeth, Kevin and Atherton, Daniel and Pittaras, Nikiforos and Frase, Heather and McGregor, Sean}, booktitle = {Proceedings of the Thirty-Seventh Annual Conference on Innovative Applications of Artificial Intelligence},title = {{Lessons for Editors of AI Incidents from the AI Incident Database}},year = {2025}}"
year: "2025"
demo: https://incidentdatabase.ai/
paper: https://arxiv.org/abs/2409.16425
hide_tags: cv-tag-conference cv-tag-talk cv-tag-poster cv-tag-peer-reviewed cv-tag-ml cv-tag-application cv-tag-safety
highlight: true
---
After years of editing AI incidents, we have learned a few things worth sharing.

**Abstract**

> As artificial intelligence (AI) systems become increasingly deployed across the world, they are also increasingly implicated in AI incidents - harm events to individuals and society. As a result, industry, civil society, and governments worldwide are developing best practices and regulations for monitoring and analyzing AI incidents. The AI Incident Database (AIID) is a project that catalogs AI incidents and supports further research by providing a platform to classify incidents for different operational and research-oriented goals. This study reviews the AIID's dataset of 750+ AI incidents and two independent taxonomies applied to these incidents to identify common challenges to indexing and analyzing AI incidents. We find that certain patterns of AI incidents present structural ambiguities that challenge incident databasing and explore how epistemic uncertainty in AI incident reporting is unavoidable. We therefore report mitigations to make incident processes more robust to uncertainty related to cause, extent of harm, severity, or technical details of implicated systems. With these findings, we discuss how to develop future AI incident reporting practices. 