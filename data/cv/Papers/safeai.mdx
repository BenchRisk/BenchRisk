---
title: "A taxonomic system for failure cause analysis of open source AI incidents"
venue: NeurIPS Workshop on Human-Centered AI (NeurIPS-22)
authors: Pittaras, N. & McGregor, S.
citation: "Pittaras, N. & McGregor, S., (2023). A taxonomic system for failure cause analysis of open source AI incidents. In Proceedings of the AAAI Workshop on SafeAI (AAAI-23). Washington, D.C.."
bibtex: "@inproceedings{McGregor2023,address = {Washington, D.C.},author = {Pittaras, N. and McGregor, S.}, booktitle = {Proceedings of the AAAI Workshop on SafeAI},title = {{A taxonomic system for failure cause analysis of open source AI incidents}},year = {2023}}"
year: "2023"
paper: https://arxiv.org/abs/2211.07280
hide_tags: cv-tag-conference cv-tag-workshop cv-tag-talk cv-tag-peer-reviewed cv-tag-ml cv-tag-application cv-tag-compsust cv-tag-safety
---
**Abstract**

> While certain industrial sectors (e.g., aviation) have a long history of mandatory incident reporting complete with analytical findings, the practice of artificial intelligence (AI) safety benefits from no such mandate and thus analyses must be performed on publicly known \"open source\" AI incidents. Although the exact causes of AI incidents are seldom known by outsiders, this work demonstrates how to apply expert knowledge on the population of incidents in the AI Incident Database (AIID) to infer the potential and likely technical causative factors that contribute to reported failures and harms. We present early work on a taxonomic system that covers a cascade of interrelated incident factors, from system goals (nearly always known) to methods / technologies (knowable in many cases) and technical failure causes (subject to expert analysis) of the implicated systems. We pair this ontology structure with a comprehensive classification workflow that leverages expert knowledge and community feedback, resulting in taxonomic annotations grounded by incident data and human expertise.
