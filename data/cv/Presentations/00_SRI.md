title: Analog Computing for Deep Neural Networks
citation: McGregor, S. Analog Computing for Deep Neural Networks. Princeton, New Jersey.
year: 2018
authors: McGregor, S.
venue: SRI International
hide_tags: cv-tag-talk cv-tag-invited cv-tag-ml cv-tag-analog-computation

This talk thematically unifies the four design dimensions of power-efficient neural network computation, including, (1) changes to the neural network specification (e.g., depthwise separable convolutions), (2) changes to the numerical expression of the neural network (e.g., quantization), (3) post-training optimization of the neural network (e.g., pruning), and (4) custom silicon (e.g., analog matrix multiplication). This talk draws from my work at [Syntiant](https://syntiant.com/) developing neural network models for ultra-low power computation on analog silicon.
