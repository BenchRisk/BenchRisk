---
name: "Sean McGregor"
avatar: "/static/images/avatar.jpg"
occupation: "Founding Director"
company: "Digital Safety Research Institute @ ULRI"
email: "newcontact@seanbmcgregor.com"
twitter: "https://twitter.com/seanmcgregor"
linkedin: "https://www.linkedin.com/in/seanbmcgregor"
github: "https://github.com/smcgregor"
status: "My current focus is standing up the [Digital Safety Research Institute](https://dsri.org/) at the [UL Research Institutes](https://ul.org/). Our research engineering efforts center on the foundational community infrastructure required for a safer digital ecosystem. Cornerstone projects include cataloguing AI harms within the [AI Incident Database](https://incidentdatabase.ai/), programmatic assessment of large language models, red teaming the release of a forthcoming LLM, and integration of comprehensive risk measures into digital system assessment."
about: "Sean McGregor is a machine learning safety researcher and founding director with the [Digital Safety Research Institute](https://dsri.org/) at the [UL Research Institutes](https://ul.org/). Prior to joining Underwriters Laboratories, Dr. McGregor launched the [AI Incident Database](https://incidentdatabase.ai/) while training edge neural network models for the neural accelerator startup [Syntiant](https://www.syntiant.com/). With an applications-centered research program spanning reinforcement learning for wildfire suppression and deep learning for heliophysics, Sean has covered a wide range of safety critical domains. Outside his day jobs, Sean's open source development work has earned media attention in the [Atlantic](https://www.theatlantic.com/technology/archive/2012/04/a-privacy-manifesto-in-code-what-if-your-emails-never-went-to-gmail-and-twitter-couldnt-see-your-tweets/255414/), [Der Spiegel](https://www.spiegel.de/netzwelt/web/datenschutz-projekt-privly-hier-liest-facebook-nicht-mit-a-825950.html), [Wired](https://www.wired.com/story/artificial-intelligence-hall-shame/), [Venture Beat](https://venturebeat.com/2021/01/15/the-ai-incident-database-wants-to-improve-the-safety-of-machine-learning/), [Vice](https://www.vice.com/en/article/m7agjq/this-database-is-finally-holding-ai-accountable), and [O'Reilly](http://radar.oreilly.com/2013/07/securing-user-content-in-the-javascriptable-web.html) while his technical publications have [appeared](/pages/vitae.html) in a variety of machine learning, HCI, ethics, and application-centered proceedings."
---

import {ReactIconInline, ReactIconLi} from "components/Icons"

### <ReactIconInline i="FaHeart" /> Social Impact Work

I am very active in the development of open source code and organizations for social impact.
Most recently I led the engineering and management of the [AI Incident Database](https://incidentdatabase.ai/),
which is a collection of AI harms and near harms realized in the real world.
The database is funded by private foundation donors and is the sole project of the Responsible AI Collaborative.
The Digital Safety Research Institute, wherein I am a director, continues to engineer the database through the
efforts of Kevin Paeth and his exceptional crew of developers.
I also previously developed the Privly Foundation, which was dedicated to online privacy
education. The foundation's activities included [developing Open Source software](https://priv.ly/),
technology workshops, and supervising student developers.

### <ReactIconInline i="FaWrench" /> Engineering

I strive to cover as much of the machine learning stack as possible from cloud infrastructure to
hardware accelerated edge runtimes. Particular strengths of mine are Python,
Keras (defining high-level APIs accelerated by hardware), Javascript,
React, TensorFlow, CI/CD, and AWS/GCP/Azure.
My engineering projects have spanned dataset aquisition, preparation,
training, and model analysis tools. A particular engineering joy of mine
is building systems (typically on the web stack) explaining the strengths and failings of
trained models.

### <ReactIconInline i="FaMicrochip" /> Past Efforts <ReactIconInline i="FaGraduationCap" />

My foundational post-doctoral work centered on making ultra-low power neural network
inference feasible through work at [Syntiant](https://syntiant.com/). To date,
Syntiant has shipped more [neural ASICS](https://en.wikipedia.org/wiki/AI_accelerator#Emergence_of_dedicated_AI_accelerator_ASICs)
than any silicon provider in the world for problems ranging from voice interfaces to sensor fusion.
I left my full-time position with Syntiant in January 2022 so I could focus on AI assurance, including efforts
related to the AI Incident Database and developing a machine learning system [testing platform](https://dyff.io/) that
was acquired by Underwriters Laboratories in 2023.
For a full _professional_ history, please view my [LinkedIn profile](https://www.linkedin.com/in/seanbmcgregor).

Prior to Syntiant, my grad school career covered four distinct areas.
First, I developed a simulator for fire, forest growth, timber sales, and weather.
Second, I developed visual analytic tools for exploring the policy space of Markov Decision Processes (MDPs),
including the wildfire simulator. Since many MDPs are defined by computationally expensive simulators,
I next developed a surrogate modeling method that brings interactive specification of policy, reward, and
optimization functions to large state space Markov Decision Processes. My final area of focus is Bayesian
policy search using the surrogate model I developed.

# Curriculum Vitae