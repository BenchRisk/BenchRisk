---
name: "Sean McGregor"
avatar: "/static/images/avatar.jpg"
occupation: "Founding Director"
company: "Digital Safety Research Institute @ ULRI"
email: "newcontact@seanbmcgregor.com"
twitter: "https://twitter.com/seanmcgregor"
linkedin: "https://www.linkedin.com/in/seanbmcgregor"
github: "https://github.com/smcgregor"
status: "My current focus is standing up the [Digital Safety Research Institute](https://dsri.org/) at the [UL Research Institutes](https://ul.org/). Our research engineering efforts center on the foundational community infrastructure required for a safer digital ecosystem. Cornerstone projects include cataloguing AI harms within the [AI Incident Database](https://incidentdatabase.ai/), programmatic assessment of large language models, red teaming the release of a forthcoming LLM, and integration of comprehensive risk measures into digital system assessment."
about: "Sean McGregor is a machine learning safety researcher and founding director with the [Digital Safety Research Institute](https://dsri.org/) at the [UL Research Institutes](https://ul.org/). Prior to joining Underwriters Laboratories, Dr. McGregor launched the [AI Incident Database](https://incidentdatabase.ai/) while training edge neural network models for the neural accelerator startup [Syntiant](https://www.syntiant.com/). With an applications-centered research program spanning reinforcement learning for wildfire suppression and deep learning for heliophysics, Sean has covered a wide range of safety critical domains. Outside his day jobs, Sean's open source development work has earned media attention in the [Atlantic](https://www.theatlantic.com/technology/archive/2012/04/a-privacy-manifesto-in-code-what-if-your-emails-never-went-to-gmail-and-twitter-couldnt-see-your-tweets/255414/), [Der Spiegel](https://www.spiegel.de/netzwelt/web/datenschutz-projekt-privly-hier-liest-facebook-nicht-mit-a-825950.html), [Wired](https://www.wired.com/story/artificial-intelligence-hall-shame/), [Venture Beat](https://venturebeat.com/2021/01/15/the-ai-incident-database-wants-to-improve-the-safety-of-machine-learning/), [Vice](https://www.vice.com/en/article/m7agjq/this-database-is-finally-holding-ai-accountable), and [O'Reilly](http://radar.oreilly.com/2013/07/securing-user-content-in-the-javascriptable-web.html) while his technical publications have [appeared](/pages/vitae.html) in a variety of machine learning, HCI, ethics, and application-centered proceedings."
---

import {ReactIconInline, ReactIconLi} from "components/Icons"

### <ReactIconInline i="FaHeart" /> Social Impact Work

I am very active in the development of open source code and organizations for social impact, including the engineering and management of the [AI Incident Database](https://incidentdatabase.ai/), which is a collection of AI harms and near harms realized in the real world. The database is funded by private foundation donors and is the sole project of the Responsible AI Collaborative. I also previously developed a federally-recognized 501c3, the Privly Foundation, dedicated to online privacy education. The foundation's activities included [developing Open Source software](https://priv.ly/), technology workshops, and supervising student developers.

### <ReactIconInline i="FaWrench" /> Engineering

I strive to cover as much of the machine learning stack as possible from cloud infrastructure to hardware accelerated edge runtimes. Particular strengths of mine are Python, Keras (defining high-level APIs accelerated by hardware), Javascript, React, TensorFlow, CI/CD, and AWS/GCP/Azure. My engineering projects have spanned dataset aquisition, preparation, training, and model analysis tools. A particular engineering joy of mine is building systems (typically on the web stack) explaining the strengths and failings of trained models.

### <ReactIconInline i="FaMicrochip" /> Machine Learning + Silicon Design Startup

My recent development and research interests were in making ultra-low power neural network inference feasible through work at [Syntiant](https://syntiant.com/). To date, Syntiant has shipped more [neural ASICS](https://en.wikipedia.org/wiki/AI_accelerator#Emergence_of_dedicated_AI_accelerator_ASICs) than any silicon provider in the world for problems ranging from voice interfaces to sensor fusion. I left my full-time position with Syntiant in January 2022 so I could focus on AI assurance. For a full _professional_ history, please view my [LinkedIn profile](https://www.linkedin.com/in/seanbmcgregor).

### <ReactIconInline i="FaGraduationCap" /> PhD Research

My grad school career covered four distinct areas. First, I developed a simulator for fire, forest growth, timber sales, and weather. Second, I developed visual analytic tools for exploring the policy space of Markov Decision Processes (MDPs), including the wildfire simulator. Since many MDPs are defined by computationally expensive simulators, I next developed a surrogate modeling method that brings interactive specification of policy, reward, and optimization functions to large state space Markov Decision Processes. My final area of focus is Bayesian policy search using the surrogate model I developed.
