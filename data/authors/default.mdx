---
name: Sean McGregor
avatar: /static/images/avatar.jpg
occupation: Founding Director
company: Digital Safety Research Institute @ ULRI
email: newcontact@seanbmcgregor.com
twitter: https://twitter.com/seanmcgregor
linkedin: https://www.linkedin.com/in/seanbmcgregor
github: https://github.com/smcgregor
---

## Status Update

My current focus is standing up the [Digital Safety Research Institute](https://dsri.org/) at the [UL Research Institutes](https://ul.org/). Our research engineering efforts center on the foundational community infrastructure required for a safer digital ecosystem. Cornerstone projects include cataloguing AI harms within the [AI Incident Database](https://incidentdatabase.ai/), programmatic assessment of large language models, red teaming the release of a forthcoming LLM, and integration of comprehensive risk measures into digital system assessment.

## About Sean

Sean McGregor is a machine learning safety researcher and founding director with the [Digital Safety Research Institute](https://dsri.org/) at the [UL Research Institutes](https://ul.org/). Prior to joining Underwriters Laboratories, Dr. McGregor launched the [AI Incident Database](https://incidentdatabase.ai/) while training edge neural network models for the neural accelerator startup [Syntiant](https://www.syntiant.com/). With an applications-centered research program spanning reinforcement learning for wildfire suppression and deep learning for heliophysics, Sean has covered a wide range of safety critical domains. Outside his day jobs, Sean's open source development work has earned media attention in the [Atlantic](https://www.theatlantic.com/technology/archive/2012/04/a-privacy-manifesto-in-code-what-if-your-emails-never-went-to-gmail-and-twitter-couldnt-see-your-tweets/255414/), [Der Spiegel](https://www.spiegel.de/netzwelt/web/datenschutz-projekt-privly-hier-liest-facebook-nicht-mit-a-825950.html), [Wired](https://www.wired.com/story/artificial-intelligence-hall-shame/), [Venture Beat](https://venturebeat.com/2021/01/15/the-ai-incident-database-wants-to-improve-the-safety-of-machine-learning/), [Vice](https://www.vice.com/en/article/m7agjq/this-database-is-finally-holding-ai-accountable), and [O'Reilly](http://radar.oreilly.com/2013/07/securing-user-content-in-the-javascriptable-web.html) while his technical publications have [appeared](/pages/vitae.html) in a variety of machine learning, HCI, ethics, and application-centered proceedings.
