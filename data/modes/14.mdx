---
number: 14
dateAdded: '2025-04-01'
dateUpdated: '2025-04-01'
short: Benchmark does not capture the distribution or variability of the task in the
  real world
example: A benchmark for evaluating summarization quality uses a fixed set of short,
  well-structured news articles from a single outlet. All inputs are grammatically
  clean, follow similar structures, and focus on non-technical content. The benchmark
  scores suggest high summarization quality. However, when the model is deployed to
  summarize real-world documents—such as messy meeting transcripts, scientific papers,
  or user-generated content with inconsistent formatting—it fails to produce coherent
  or accurate summaries. The benchmark user, trusting the strong results, integrates
  the model into a productivity suite, leading to summaries that are frequently misleading,
  incomplete, or incoherent in actual usage scenarios.
severity: 0.6
stage: (2) Prompt Generation
dimension: Comprehensiveness
about: todo
---

todo