---
number: 44
dateAdded: '2025-04-01'
dateUpdated: '2025-04-01'
short: Test set leaks out to the general internet
example: A benchmark of challenging multi-hop reasoning questions is leaked by a disgruntled
  former employee. Over time, these questions, or paraphrased versions of them, begin
  to appear on various online forums, study websites, and even in synthetic datasets
  used for pre-training language models. As a result, new models are inadvertently
  (or intentionally) trained on data that overlaps with the benchmark, leading to
  artificially inflated scores that don't reflect genuine reasoning ability. A benchmark
  user, unaware of this data contamination, might choose a seemingly high-performing
  model that simply memorized the leaked test set, only to find it performs poorly
  on novel reasoning tasks in real-world applications.
severity: 0.9
stage: (7) Upkeep
dimension: Longevity
about: todo
---

todo